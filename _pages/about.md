---
permalink: /
title: "Hi, I'm Yiyu Wang (ç‹ä¸€å®‡) ğŸ‘‹"
excerpt: "Ph.D. Student at HKUST(GZ) focusing on Precise & Efficient Video Understanding"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

<div style="background-color: #f3f6f9; border-radius: 8px; padding: 20px; border-left: 5px solid #003366; margin-bottom: 25px;">
  <h3 style="margin-top: 0; color: #003366;">ğŸš€ Precise & Efficient Video Understanding</h3>
  <p style="font-size: 1.1em; margin-bottom: 10px;">
    I am a <strong>Ph.D. Student</strong> at <a href="https://www.hkust-gz.edu.cn/">HKUST(GZ)</a>, advised by Prof. Linfeng Zhang and Prof. Xuming Hu.
  </p>
  <p>
    My research aims to achieve <strong>Precise and Efficient Video Understanding</strong>. [cite_start]I currently focus on accelerating <strong>Video Large Language Models (VideoLLMs)</strong> via Token Compression and Data-Centric AI techniques[cite: 35, 37].
  </p>
  
  <div style="margin-top: 15px;">
    <img src="https://img.shields.io/badge/Institution-HKUST(GZ)-003366?style=flat-square&logo=google-scholar" alt="Institution">
    <img src="https://img.shields.io/badge/Focus-VideoLLMs-db545a?style=flat-square" alt="Research Interest">
    <img src="https://img.shields.io/badge/Focus-Efficiency-success?style=flat-square" alt="Efficiency">
  </div>
</div>

[cite_start]Previously, I was a Research Intern at **Shanghai Jiao Tong University (SJTU)** (EPIC Lab)[cite: 8, 10].

---

## ğŸ”¥ News & Updates

<ul>
  <li>
    <span style="background-color: #db545a; color: white; padding: 2px 6px; border-radius: 4px; font-weight: bold; font-size: 0.85em;">2025.10</span> 
    [cite_start]ğŸ† <strong>Paper Accepted!</strong> Our work <em>"Video Compression Commander"</em> is accepted to <strong>EMNLP 2025 Main Conference</strong>[cite: 25, 26].
  </li>
  <li>
    <span style="background-color: #28a745; color: white; padding: 2px 6px; border-radius: 4px; font-weight: bold; font-size: 0.85em;">Submitted</span> 
    [cite_start]ğŸ¤ Collaborated on <em>"Variation-aware Vision Token Dropping"</em>, submitted to <strong>CVPR 2026</strong>[cite: 30].
  </li>
  <li>
    <span style="background-color: #28a745; color: white; padding: 2px 6px; border-radius: 4px; font-weight: bold; font-size: 0.85em;">Submitted</span> 
    [cite_start]ğŸ¤ Co-authored <em>"Are We Using the Right Benchmark for Visual Token Compression?"</em>, submitted to <strong>ACL 2025</strong>[cite: 31].
  </li>
  <li>
    <span style="background-color: #28a745; color: white; padding: 2px 6px; border-radius: 4px; font-weight: bold; font-size: 0.85em;">Submitted</span> 
    [cite_start]ğŸ“Š Collaborated on Data-Centric Compression research, submitted to <strong>ACL 2025</strong>[cite: 32].
  </li>
  <li>
    <span style="background-color: #17a2b8; color: white; padding: 2px 6px; border-radius: 4px; font-weight: bold; font-size: 0.85em;">Report</span> 
    [cite_start]ğŸ‘“ Released Technical Report: <em>"AI for Service: Proactive Assistance with AI Glasses"</em>[cite: 27, 28].
  </li>
</ul>

---

## ğŸ“ Selected Publications


<div style="box-shadow: 0 4px 8px 0 rgba(0,0,0,0.1); transition: 0.3s; border-radius: 5px; padding: 20px; margin-bottom: 20px; border-left: 5px solid #db545a; background-color: #fff;">
  <h3 style="margin-top: 0; margin-bottom: 10px;">
    <a href="LINK-TO-PAPER" style="text-decoration: none; color: #333;">Video Compression Commander: Plug-and-Play Inference Acceleration for Video LLMs</a>
  </h3>
  <div style="margin-bottom: 10px;">
    Xuyang Liu*, <strong>Yiyu Wang*</strong>, Junpeng Ma, Linfeng Zhang.
    <br>
    <span style="color: #db545a; font-weight: bold;">EMNLP 2025 Main Conference</span>
  </div>
  <p style="font-size: 0.95em; color: #555;">
    Proposed <strong>VidComÂ²</strong>, a training-free framework that accelerates VideoLLMs by adaptively adjusting compression based on frame uniqueness. [cite_start]Achieved <strong>99.6% performance retention</strong> with only <strong>25% tokens</strong> and <strong>70.8% latency reduction</strong>[cite: 37, 39].
  </p>
  <div>
    <a href="LINK-TO-PAPER" style="text-decoration: none;"><img src="https://img.shields.io/badge/Paper-EMNLP'25-db545a?style=flat&logo=semanticscholar" alt="Paper"></a>
    <a href="LINK-TO-CODE" style="text-decoration: none;"><img src="https://img.shields.io/badge/Code-GitHub-181717?style=flat&logo=github" alt="Code"></a>
  </div>
</div>

<div style="box-shadow: 0 4px 8px 0 rgba(0,0,0,0.1); transition: 0.3s; border-radius: 5px; padding: 20px; margin-bottom: 20px; border-left: 5px solid #007bff; background-color: #fff;">
  <h3 style="margin-top: 0; margin-bottom: 10px;">
    <a href="LINK-TO-PAPER" style="text-decoration: none; color: #333;">Accelerating Streaming Video Large Language Models via Hierarchical Token Compression</a>
  </h3>
  <div style="margin-bottom: 10px;">
    <strong>Yiyu Wang</strong>, Xuyang Liu, Xiyan Gui, Xinying Lin, Boxue Yang, Chenfei Liao, Tailai Chen, Linfeng Zhang.
    <br>
    <span style="color: #007bff; font-weight: bold;">arXiv Preprint 2025</span>
  </div>
  <p style="font-size: 0.95em; color: #555;">
    [cite_start]Addressing the challenge of processing infinite video streams by implementing hierarchical token compression, enabling efficient long-term video understanding[cite: 24].
  </p>
  <div>
    <a href="LINK-TO-PDF" style="text-decoration: none;"><img src="https://img.shields.io/badge/Paper-arXiv-B31B1B?style=flat&logo=arxiv" alt="Paper"></a>
    <a href="LINK-TO-CODE" style="text-decoration: none;"><img src="https://img.shields.io/badge/Code-GitHub-181717?style=flat&logo=github" alt="Code"></a>
  </div>
</div>

---


## ğŸ’» Open Source

I actively contribute to the community by maintaining resource lists:
* [cite_start]â­ **[Awesome Token-level Model Compression](https://github.com/your-username/repo1)** (173+ Stars) [cite: 42]
* [cite_start]â­ **[Awesome Generation Acceleration](https://github.com/your-username/repo2)** (353+ Stars) [cite: 43]
