---
permalink: /
title: "Hi, I'm Yiyu Wang (ç‹ä¸€å®‡) ğŸ‘‹"
excerpt: "Ph.D. Student at HKUST(GZ) focusing on Efficient VideoLLMs"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

<div style="background-color: #f3f6f9; border-radius: 8px; padding: 20px; border-left: 5px solid #003366; margin-bottom: 25px;">
  <h3 style="margin-top: 0; color: #003366;">ğŸš€ Efficient Video Understanding & Generation</h3>
  <p style="font-size: 1.1em; margin-bottom: 10px;">
    I am a <strong>Ph.D. Student</strong> at <a href="https://www.hkust-gz.edu.cn/">HKUST(GZ)</a>, advised by Prof. Linfeng Zhang and Prof. Xuming Hu.
  </p>
  <p>
    My research aims to make <strong>Video Large Language Models (VideoLLMs)</strong> faster and lighter. I focus on <strong>Token Compression</strong>, <strong>KV Cache Optimization</strong>, and <strong>Data-Centric AI</strong> to enable long-context video understanding on consumer-grade hardware.
  </p>
  
  <div style="margin-top: 15px;">
    <img src="https://img.shields.io/badge/Institution-HKUST(GZ)-003366?style=flat-square&logo=google-scholar" alt="Institution">
    <img src="https://img.shields.io/badge/Focus-VideoLLMs-db545a?style=flat-square" alt="Research Interest">
    <img src="https://img.shields.io/github/stars/your-username/Awesome-Token-level-Model-Compression?style=social" alt="GitHub Stars">
  </div>
</div>

Previously, I was a Research Intern at **Shanghai Jiao Tong University (SJTU)** (EPIC Lab).

---

## ğŸ”¥ News & Updates

<ul>
  <li>
    <span style="background-color: #db545a; color: white; padding: 2px 6px; border-radius: 4px; font-weight: bold; font-size: 0.85em;">2025.10</span> 
    ğŸ† <strong>Paper Accepted!</strong> Our work <em>"Video Compression Commander"</em> is accepted to <strong>EMNLP 2025 Main Conference</strong>.
  </li>
  <li>
    <span style="background-color: #28a745; color: white; padding: 2px 6px; border-radius: 4px; font-weight: bold; font-size: 0.85em;">Submitted</span> 
    ğŸ¤ Collaborated on <em>"Variation-aware Vision Token Dropping"</em>, submitted to <strong>CVPR 2026</strong>.
  </li>
  <li>
    <span style="background-color: #28a745; color: white; padding: 2px 6px; border-radius: 4px; font-weight: bold; font-size: 0.85em;">Submitted</span> 
    ğŸ¤ Co-authored <em>"Are We Using the Right Benchmark for Visual Token Compression?"</em>, submitted to <strong>ACL 2025</strong>.
  </li>
  <li>
    <span style="background-color: #28a745; color: white; padding: 2px 6px; border-radius: 4px; font-weight: bold; font-size: 0.85em;">Submitted</span> 
    ğŸ“Š Collaborated on Data-Centric Compression research, submitted to <strong>ACL 2025</strong>.
  </li>
  <li>
    <span style="background-color: #17a2b8; color: white; padding: 2px 6px; border-radius: 4px; font-weight: bold; font-size: 0.85em;">Report</span> 
    ğŸ‘“ Released Technical Report: <em>"AI for Service: Proactive Assistance with AI Glasses"</em>.
  </li>
</ul>

---

## ğŸ“ Selected Publications

<div style="margin-bottom: 10px; font-size: 0.9em; color: #666;">
  <em>* denotes equal contribution. Full list available in <a href="files/cv.pdf">CV</a>.</em>
</div>

<div style="box-shadow: 0 4px 8px 0 rgba(0,0,0,0.1); transition: 0.3s; border-radius: 5px; padding: 20px; margin-bottom: 20px; border-left: 5px solid #db545a; background-color: #fff;">
  <h3 style="margin-top: 0; margin-bottom: 10px;">
    <a href="LINK-TO-PAPER" style="text-decoration: none; color: #333;">Video Compression Commander: Plug-and-Play Inference Acceleration for Video LLMs</a>
  </h3>
  <div style="margin-bottom: 10px;">
    Xuyang Liu*, <strong>Yiyu Wang*</strong>, Junpeng Ma, Linfeng Zhang.
    <br>
    <span style="color: #db545a; font-weight: bold;">EMNLP 2025 Main Conference</span>
  </div>
  <p style="font-size: 0.95em; color: #555;">
    Proposed <strong>VidComÂ²</strong>, a training-free framework that accelerates VideoLLMs by adaptively adjusting compression based on frame uniqueness. Achieved <strong>99.6% performance retention</strong> with only <strong>25% tokens</strong>.
  </p>
  <div>
    <a href="LINK-TO-PAPER" style="text-decoration: none;"><img src="https://img.shields.io/badge/Paper-EMNLP'25-db545a?style=flat&logo=semanticscholar" alt="Paper"></a>
    <a href="LINK-TO-CODE" style="text-decoration: none;"><img src="https://img.shields.io/badge/Code-GitHub-181717?style=flat&logo=github" alt="Code"></a>
  </div>
</div>

<div style="box-shadow: 0 4px 8px 0 rgba(0,0,0,0.1); transition: 0.3s; border-radius: 5px; padding: 20px; margin-bottom: 20px; border-left: 5px solid #007bff; background-color: #fff;">
  <h3 style="margin-top: 0; margin-bottom: 10px;">
    <a href="LINK-TO-PAPER" style="text-decoration: none; color: #333;">Accelerating Streaming Video Large Language Models via Hierarchical Token Compression</a>
  </h3>
  <div style="margin-bottom: 10px;">
    <strong>Yiyu Wang</strong>, Xuyang Liu, Xiyan Gui, Xinying Lin, Boxue Yang, Chenfei Liao, Tailai Chen, Linfeng Zhang.
    <br>
    <span style="color: #007bff; font-weight: bold;">arXiv Preprint 2025</span>
  </div>
  <p style="font-size: 0.95em; color: #555;">
    Addressing the challenge of processing infinite video streams by implementing hierarchical token compression, enabling efficient long-term video understanding.
  </p>
  <div>
    <a href="LINK-TO-PDF" style="text-decoration: none;"><img src="https://img.shields.io/badge/Paper-arXiv-B31B1B?style=flat&logo=arxiv" alt="Paper"></a>
    <a href="LINK-TO-CODE" style="text-decoration: none;"><img src="https://img.shields.io/badge/Code-GitHub-181717?style=flat&logo=github" alt="Code"></a>
  </div>
</div>

---



## ğŸ’» Open Source

* [cite_start]**[Awesome Token-level Model Compression](https://github.com/your-username/repo1)** (â­ 173+) [cite: 42]
* [cite_start]**[Awesome Generation Acceleration](https://github.com/your-username/repo2)** (â­ 353+) [cite: 43]
